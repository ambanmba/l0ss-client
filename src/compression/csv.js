/**
 * CSV compression engine with lossy optimizations
 */

/**
 * Compress CSV with specified loss level
 */
export async function compressCSV(content, lossLevel = 'moderate', customOptions = {}) {
  const operations = [];

  // Parse CSV
  const lines = content.split('\n').filter(line => line.trim());
  if (lines.length === 0) {
    throw new Error('Empty CSV file');
  }

  let header = lines[0];
  let dataLines = lines.slice(1);

  const originalSize = content.length;

  let result;
  switch (lossLevel) {
    case 'minimal':
      result = applyMinimalCSVCompression(header, dataLines, operations, customOptions);
      break;
    case 'moderate':
      result = applyModerateCSVCompression(header, dataLines, operations, customOptions);
      break;
    case 'aggressive':
      result = applyAggressiveCSVCompression(header, dataLines, operations, customOptions);
      break;
    default:
      throw new Error('Invalid loss level');
  }

  header = result.header;
  dataLines = result.dataLines;

  const compressed = [header, ...dataLines].join('\n');

  return {
    compressed,
    operations,
    originalSize,
    compressedSize: compressed.length
  };
}

/**
 * Minimal CSV compression
 */
function applyMinimalCSVCompression(header, dataLines, operations, customOptions) {
  // Remove empty rows
  if (customOptions.removeEmptyRows !== false) {
    const originalCount = dataLines.length;
    dataLines = dataLines.filter(line => {
      const fields = line.split(',');
      return fields.some(field => field.trim() !== '');
    });

    if (dataLines.length < originalCount) {
      operations.push({
        type: 'remove_empty_rows',
        count: originalCount - dataLines.length,
        reversible: false,
        impact: 'low'
      });
    }
  }

  // Trim whitespace from fields
  const trimmedCount = { value: 0 };
  dataLines = dataLines.map(line => {
    const fields = line.split(',').map(field => {
      const trimmed = field.trim();
      if (trimmed !== field) trimmedCount.value++;
      return trimmed;
    });
    return fields.join(',');
  });

  if (trimmedCount.value > 0) {
    operations.push({
      type: 'trim_fields',
      count: trimmedCount.value,
      reversible: false,
      impact: 'low'
    });
  }

  return { header, dataLines };
}

/**
 * Moderate CSV compression
 */
function applyModerateCSVCompression(header, dataLines, operations, customOptions) {
  // First apply minimal compression
  let result = applyMinimalCSVCompression(header, dataLines, operations, customOptions);
  header = result.header;
  dataLines = result.dataLines;

  // Deduplicate rows
  if (customOptions.deduplicateRows !== false) {
    const originalCount = dataLines.length;
    const uniqueRows = new Set(dataLines);
    dataLines = Array.from(uniqueRows);

    if (dataLines.length < originalCount) {
      operations.push({
        type: 'deduplicate_rows',
        count: originalCount - dataLines.length,
        reversible: false,
        impact: 'medium'
      });
    }
  }

  // Round numeric values
  if (customOptions.roundNumbers !== false) {
    const roundedCount = { value: 0 };
    dataLines = dataLines.map(line => {
      const fields = line.split(',').map(field => {
        const num = parseFloat(field);
        if (!isNaN(num) && field.trim() !== '') {
          roundedCount.value++;
          return num.toFixed(2);
        }
        return field;
      });
      return fields.join(',');
    });

    if (roundedCount.value > 0) {
      operations.push({
        type: 'round_numbers',
        decimals: 2,
        count: roundedCount.value,
        reversible: false,
        impact: 'medium'
      });
    }
  }

  // Apply delta encoding to numeric columns (for time-series/sequential data)
  // Inspired by: Gorilla (Facebook), Daniel Lemire's frame-of-reference encoding
  // References:
  // - "Effective compression using frame-of-reference and delta coding" (Lemire, 2012)
  // - "The Design of Fast Delta Encoding for Delta Compression" (ACM TOS 2024)
  // - https://en.wikipedia.org/wiki/Delta_encoding
  if (customOptions.deltaEncoding !== false && dataLines.length > 1) {
    const deltaEncodedColumns = applyDeltaEncoding(header, dataLines);

    if (deltaEncodedColumns.count > 0) {
      header = deltaEncodedColumns.header;
      dataLines = deltaEncodedColumns.dataLines;

      operations.push({
        type: 'delta_encoding',
        columns: deltaEncodedColumns.count,
        reversible: true, // Can be reversed using cumulative sum
        impact: 'medium',
        description: `Applied delta encoding to ${deltaEncodedColumns.count} numeric column(s)`
      });
    }
  }

  // Apply dictionary encoding to string columns with repeated values
  // Inspired by: BtrBlocks (SIGMOD 2023), SAP HANA dictionary compression
  // References:
  // - "BtrBlocks: Efficient Columnar Compression for Data Lakes" (SIGMOD 2023)
  // - https://github.com/maxi-k/btrblocks
  // - https://en.wikipedia.org/wiki/Dictionary_coder
  if (customOptions.dictionaryEncoding !== false && dataLines.length > 1) {
    const dictionaryResult = applyDictionaryEncoding(header, dataLines);

    if (dictionaryResult.count > 0) {
      header = dictionaryResult.header;
      dataLines = dictionaryResult.dataLines;

      operations.push({
        type: 'dictionary_encoding',
        columns: dictionaryResult.count,
        unique_values_saved: dictionaryResult.compressionRatio,
        reversible: true, // Can be reversed using dictionary lookup
        impact: 'medium',
        description: `Applied dictionary encoding to ${dictionaryResult.count} string column(s)`
      });
    }
  }

  // Remove low-variance columns (all values are the same)
  if (customOptions.removeLowVarianceColumns !== false && dataLines.length > 0) {
    const firstLine = dataLines[0].split(',');
    const columnsToKeep = [];

    for (let colIndex = 0; colIndex < firstLine.length; colIndex++) {
      const values = new Set();
      dataLines.forEach(line => {
        const fields = line.split(',');
        if (fields[colIndex]) {
          values.add(fields[colIndex].trim());
        }
      });

      // Keep column if it has more than one unique value
      if (values.size > 1) {
        columnsToKeep.push(colIndex);
      }
    }

    if (columnsToKeep.length < firstLine.length) {
      dataLines = dataLines.map(line => {
        const fields = line.split(',');
        return columnsToKeep.map(i => fields[i]).join(',');
      });

      operations.push({
        type: 'remove_low_variance_columns',
        count: firstLine.length - columnsToKeep.length,
        reversible: false,
        impact: 'medium'
      });
    }
  }

  // Truncate long text fields
  if (customOptions.truncateText !== false) {
    const maxLength = customOptions.maxTextLength || 50;
    const truncatedCount = { value: 0 };

    dataLines = dataLines.map(line => {
      const fields = line.split(',').map(field => {
        // Only truncate non-numeric text fields
        if (isNaN(parseFloat(field)) && field.length > maxLength) {
          truncatedCount.value++;
          return field.substring(0, maxLength) + '...';
        }
        return field;
      });
      return fields.join(',');
    });

    if (truncatedCount.value > 0) {
      operations.push({
        type: 'truncate_long_text',
        maxLength: maxLength,
        count: truncatedCount.value,
        reversible: false,
        impact: 'medium'
      });
    }
  }

  return { header, dataLines };
}

/**
 * Aggressive CSV compression
 */
function applyAggressiveCSVCompression(header, dataLines, operations, customOptions) {
  // First apply moderate compression
  let result = applyModerateCSVCompression(header, dataLines, operations, customOptions);
  header = result.header;
  dataLines = result.dataLines;

  // Keep only first N columns
  if (customOptions.keepFirstNColumns && dataLines.length > 0) {
    const maxColumns = customOptions.maxColumns || 5;
    const firstLine = dataLines[0].split(',');

    if (firstLine.length > maxColumns) {
      dataLines = dataLines.map(line => {
        const fields = line.split(',');
        return fields.slice(0, maxColumns).join(',');
      });

      operations.push({
        type: 'keep_first_n_columns',
        maxColumns: maxColumns,
        removed: firstLine.length - maxColumns,
        reversible: false,
        impact: 'high'
      });
    }
  }

  // Sample rows (keep every nth row)
  if (customOptions.sampleRows && dataLines.length > 10) {
    const originalCount = dataLines.length;
    const sampleRate = customOptions.sampleRate || 5; // Keep every 5th row

    dataLines = dataLines.filter((_, index) => index % sampleRate === 0);

    if (dataLines.length < originalCount) {
      operations.push({
        type: 'sample_rows',
        sampleRate: sampleRate,
        original: originalCount,
        sampled: dataLines.length,
        reversible: false,
        impact: 'high'
      });
    }
  }

  // Remove non-essential columns (if specified)
  if (customOptions.removeNonEssentialColumns && customOptions.essentialColumnIndices) {
    const keepIndices = customOptions.essentialColumnIndices;
    const firstLine = dataLines[0].split(',');

    dataLines = dataLines.map(line => {
      const fields = line.split(',');
      return keepIndices.map(i => fields[i] || '').join(',');
    });

    operations.push({
      type: 'remove_non_essential_columns',
      kept: keepIndices.length,
      removed: firstLine.length - keepIndices.length,
      reversible: false,
      impact: 'high'
    });
  }

  // Remove statistical outliers
  if (customOptions.removeOutliers) {
    const numericColumns = detectNumericColumns(dataLines);

    numericColumns.forEach(colIndex => {
      const values = dataLines.map(line => {
        const fields = line.split(',');
        return parseFloat(fields[colIndex]);
      }).filter(v => !isNaN(v));

      if (values.length < 5) return; // Need enough data for statistics

      const mean = values.reduce((a, b) => a + b, 0) / values.length;
      const stdDev = Math.sqrt(
        values.reduce((sq, n) => sq + Math.pow(n - mean, 2), 0) / values.length
      );

      const threshold = 2; // 2 standard deviations
      const originalCount = dataLines.length;

      dataLines = dataLines.filter(line => {
        const fields = line.split(',');
        const value = parseFloat(fields[colIndex]);
        if (isNaN(value)) return true;
        return Math.abs(value - mean) <= threshold * stdDev;
      });

      if (dataLines.length < originalCount) {
        operations.push({
          type: 'remove_outliers',
          column: colIndex,
          count: originalCount - dataLines.length,
          reversible: false,
          impact: 'high'
        });
      }
    });
  }

  // Statistical sampling
  if (customOptions.statisticalSampling && dataLines.length > 100) {
    const originalCount = dataLines.length;
    const sampleSize = Math.max(50, Math.floor(originalCount * 0.3)); // Keep 30% or min 50

    // Systematic sampling
    const step = Math.floor(originalCount / sampleSize);
    dataLines = dataLines.filter((_, index) => index % step === 0);

    operations.push({
      type: 'statistical_sampling',
      original: originalCount,
      sampled: dataLines.length,
      reversible: false,
      impact: 'high'
    });
  }

  return { header, dataLines };
}

/**
 * Detect which columns contain numeric data
 */
function detectNumericColumns(dataLines) {
  if (dataLines.length === 0) return [];

  const firstLine = dataLines[0].split(',');
  const numericColumns = [];

  firstLine.forEach((_, colIndex) => {
    let numericCount = 0;
    const sampleSize = Math.min(10, dataLines.length);

    for (let i = 0; i < sampleSize; i++) {
      const fields = dataLines[i].split(',');
      if (!isNaN(parseFloat(fields[colIndex]))) {
        numericCount++;
      }
    }

    // If more than 80% are numeric, consider it a numeric column
    if (numericCount / sampleSize > 0.8) {
      numericColumns.push(colIndex);
    }
  });

  return numericColumns;
}

/**
 * Apply delta encoding to numeric columns
 *
 * Delta encoding stores the difference between consecutive values instead of absolute values.
 * This is particularly effective for time-series data, sequential IDs, timestamps, and
 * monotonically increasing values.
 *
 * Algorithm:
 * 1. Identify numeric columns (all values in column are numbers)
 * 2. For each numeric column, calculate deltas: delta[i] = value[i] - value[i-1]
 * 3. Store first value as-is (base/reference value)
 * 4. Replace subsequent values with their deltas
 *
 * Example:
 * Original: [100, 105, 110, 108, 112]
 * Encoded:  [100, +5, +5, -2, +4]
 *
 * Benefits:
 * - Smaller numbers = fewer digits = less storage
 * - Works well with subsequent compression (gzip, etc.)
 * - Reversible: cumulative sum restores original values
 *
 * References:
 * - Gorilla time-series database (Facebook)
 * - "Effective compression using frame-of-reference and delta coding" (Lemire, 2012)
 * - "The Design of Fast Delta Encoding" (ACM TOS, 2024)
 *
 * @param {string} header - CSV header row
 * @param {Array<string>} dataLines - CSV data rows
 * @returns {Object} { header, dataLines, count } - Modified CSV and count of encoded columns
 */
function applyDeltaEncoding(header, dataLines) {
  if (dataLines.length < 2) {
    return { header, dataLines, count: 0 };
  }

  const headerFields = header.split(',');
  const numColumns = headerFields.length;

  // Identify which columns are numeric (all values are numbers)
  const numericColumns = [];
  for (let colIndex = 0; colIndex < numColumns; colIndex++) {
    let isNumeric = true;
    let hasVariance = false;
    let prevValue = null;

    for (const line of dataLines) {
      const fields = line.split(',');
      const value = fields[colIndex];
      const num = parseFloat(value);

      if (isNaN(num) || value.trim() === '') {
        isNumeric = false;
        break;
      }

      // Check if values have variance (not all the same)
      if (prevValue !== null && Math.abs(num - prevValue) > 0.01) {
        hasVariance = true;
      }
      prevValue = num;
    }

    // Only apply delta encoding to numeric columns with variance
    if (isNumeric && hasVariance) {
      numericColumns.push(colIndex);
    }
  }

  if (numericColumns.length === 0) {
    return { header, dataLines, count: 0 };
  }

  // Apply delta encoding to identified columns
  const encodedLines = dataLines.map((line, rowIndex) => {
    const fields = line.split(',');

    // For each numeric column, replace with delta
    for (const colIndex of numericColumns) {
      const currentValue = parseFloat(fields[colIndex]);

      if (rowIndex === 0) {
        // First row: keep original value (base/reference)
        fields[colIndex] = currentValue.toString();
      } else {
        // Subsequent rows: calculate delta from previous row
        const prevLine = dataLines[rowIndex - 1];
        const prevFields = prevLine.split(',');
        const prevValue = parseFloat(prevFields[colIndex]);
        const delta = currentValue - prevValue;

        // Store delta with sign prefix for clarity
        fields[colIndex] = (delta >= 0 ? '+' : '') + delta.toFixed(2);
      }
    }

    return fields.join(',');
  });

  // Update header to indicate delta-encoded columns
  const updatedHeader = headerFields.map((field, index) => {
    if (numericColumns.includes(index)) {
      return `${field}(Î”)`; // Add delta symbol to indicate encoding
    }
    return field;
  }).join(',');

  return {
    header: updatedHeader,
    dataLines: encodedLines,
    count: numericColumns.length
  };
}

/**
 * Apply dictionary encoding to string columns
 *
 * Dictionary encoding replaces repeated string values with integer codes,
 * significantly reducing file size when columns have many repeated values.
 *
 * Algorithm:
 * 1. Identify string columns (non-numeric columns with repeated values)
 * 2. For each column, build a dictionary mapping unique values to codes (0, 1, 2, ...)
 * 3. Replace all values with their dictionary codes
 * 4. Store dictionary as header comment or separate structure
 *
 * Example:
 * Original: ["USA", "Canada", "USA", "Mexico", "USA", "Canada"]
 * Dictionary: {0: "USA", 1: "Canada", 2: "Mexico"}
 * Encoded: [0, 1, 0, 2, 0, 1]
 *
 * Benefits:
 * - Long strings replaced with short integer codes
 * - Compression ratio depends on repetition rate
 * - Particularly effective for categorical data (country, status, type, etc.)
 * - Works well when unique values << total values
 *
 * References:
 * - BtrBlocks (SIGMOD 2023): "Efficient Columnar Compression for Data Lakes"
 * - SAP HANA Dictionary Compression
 * - https://en.wikipedia.org/wiki/Dictionary_coder
 *
 * @param {string} header - CSV header row
 * @param {Array<string>} dataLines - CSV data rows
 * @returns {Object} { header, dataLines, count, compressionRatio } - Modified CSV and encoding stats
 */
function applyDictionaryEncoding(header, dataLines) {
  if (dataLines.length < 2) {
    return { header, dataLines, count: 0, compressionRatio: 0 };
  }

  const headerFields = header.split(',');
  const numColumns = headerFields.length;

  // Identify which columns are string columns with repetition
  const stringColumnsWithRepetition = [];

  for (let colIndex = 0; colIndex < numColumns; colIndex++) {
    const values = [];
    let isNumericColumn = true;

    // Collect all values in this column
    for (const line of dataLines) {
      const fields = line.split(',');
      const value = fields[colIndex] ? fields[colIndex].trim() : '';
      values.push(value);

      // Check if this is a numeric column (delta encoding should handle these)
      if (value !== '' && isNaN(parseFloat(value))) {
        isNumericColumn = false;
      }
    }

    // Skip numeric columns (delta encoding handles those)
    if (isNumericColumn) {
      continue;
    }

    // Count unique values
    const uniqueValues = new Set(values);

    // Only apply dictionary encoding if:
    // 1. Column has repeated values (unique count < total count)
    // 2. Unique values < 80% of total values (significant repetition)
    // 3. At least 3 unique values (avoid low-variance columns handled elsewhere)
    const repetitionRate = uniqueValues.size / values.length;
    if (uniqueValues.size >= 3 && uniqueValues.size < values.length && repetitionRate < 0.8) {
      stringColumnsWithRepetition.push({
        index: colIndex,
        uniqueCount: uniqueValues.size,
        totalCount: values.length,
        repetitionRate
      });
    }
  }

  if (stringColumnsWithRepetition.length === 0) {
    return { header, dataLines, count: 0, compressionRatio: 0 };
  }

  // Build dictionaries for each column and apply encoding
  const encodedLines = dataLines.map(line => {
    const fields = line.split(',');

    for (const colInfo of stringColumnsWithRepetition) {
      const colIndex = colInfo.index;
      const value = fields[colIndex] ? fields[colIndex].trim() : '';

      // Build dictionary on first pass (we'll rebuild properly below)
      // For now, just mark that we'll encode this column
    }

    return fields.join(',');
  });

  // Build dictionaries for each column
  const columnDictionaries = [];

  for (const colInfo of stringColumnsWithRepetition) {
    const colIndex = colInfo.index;
    const uniqueValues = new Set();

    // Collect unique values
    for (const line of dataLines) {
      const fields = line.split(',');
      const value = fields[colIndex] ? fields[colIndex].trim() : '';
      uniqueValues.add(value);
    }

    // Create dictionary: value -> code
    const dictionary = {};
    const reverseDictionary = {};
    let code = 0;

    for (const value of Array.from(uniqueValues).sort()) {
      dictionary[value] = code;
      reverseDictionary[code] = value;
      code++;
    }

    columnDictionaries.push({
      colIndex,
      dictionary,
      reverseDictionary
    });
  }

  // Apply encoding using dictionaries
  const finalEncodedLines = dataLines.map(line => {
    const fields = line.split(',');

    for (const dictInfo of columnDictionaries) {
      const colIndex = dictInfo.colIndex;
      const value = fields[colIndex] ? fields[colIndex].trim() : '';
      fields[colIndex] = dictInfo.dictionary[value].toString();
    }

    return fields.join(',');
  });

  // Update header to indicate dictionary-encoded columns
  const updatedHeader = headerFields.map((field, index) => {
    if (columnDictionaries.some(d => d.colIndex === index)) {
      return `${field}(D)`; // Add dictionary symbol to indicate encoding
    }
    return field;
  }).join(',');

  // Calculate compression ratio (average unique values across all encoded columns)
  const avgCompressionRatio = stringColumnsWithRepetition.length > 0
    ? (stringColumnsWithRepetition.reduce((sum, col) => sum + col.repetitionRate, 0) / stringColumnsWithRepetition.length * 100).toFixed(1)
    : 0;

  return {
    header: updatedHeader,
    dataLines: finalEncodedLines,
    count: stringColumnsWithRepetition.length,
    compressionRatio: parseFloat(avgCompressionRatio)
  };
}

/**
 * Get custom options for CSV compression
 */
export function getCSVOptions() {
  return {
    removeEmptyRows: {
      default: true,
      impact: 'low',
      description: 'Remove rows with all empty values',
      reversible: false
    },
    deduplicateRows: {
      default: true,
      impact: 'medium',
      description: 'Remove duplicate rows',
      reversible: false
    },
    roundNumbers: {
      default: true,
      impact: 'medium',
      description: 'Round numbers to 2 decimal places',
      reversible: false
    },
    deltaEncoding: {
      default: true,
      impact: 'medium',
      description: 'Apply delta encoding to numeric columns (stores differences between consecutive values)',
      reversible: true
    },
    dictionaryEncoding: {
      default: true,
      impact: 'medium',
      description: 'Apply dictionary encoding to string columns (replaces repeated values with integer codes)',
      reversible: true
    },
    removeLowVarianceColumns: {
      default: true,
      impact: 'medium',
      description: 'Remove columns where all values are the same',
      reversible: false
    },
    truncateText: {
      default: true,
      impact: 'medium',
      description: 'Truncate long text fields to 50 characters',
      reversible: false
    },
    maxTextLength: {
      default: 50,
      impact: 'medium',
      description: 'Maximum length for text fields before truncation',
      reversible: false
    },
    keepFirstNColumns: {
      default: false,
      impact: 'high',
      description: 'Keep only the first N columns',
      reversible: false
    },
    maxColumns: {
      default: 5,
      impact: 'high',
      description: 'Number of columns to keep (when keepFirstNColumns is enabled)',
      reversible: false
    },
    sampleRows: {
      default: false,
      impact: 'high',
      description: 'Sample rows (keep every nth row)',
      reversible: false
    },
    sampleRate: {
      default: 5,
      impact: 'high',
      description: 'Keep every nth row (when sampleRows is enabled)',
      reversible: false
    },
    removeNonEssentialColumns: {
      default: false,
      impact: 'high',
      description: 'Remove all columns except specified essential ones',
      reversible: false
    },
    essentialColumnIndices: {
      default: [],
      impact: 'high',
      description: 'Array of column indices to keep (when removeNonEssentialColumns is enabled)',
      reversible: false
    },
    removeOutliers: {
      default: false,
      impact: 'high',
      description: 'Remove statistical outliers (beyond 2 standard deviations)',
      reversible: false
    },
    statisticalSampling: {
      default: false,
      impact: 'high',
      description: 'Use statistical sampling to reduce row count (keep 30%)',
      reversible: false
    }
  };
}
